{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nName: Daryl Hou\\nEmaiL: daryl.hou08@myhunter.cuny.edu\\npod: rear left\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Name: Daryl Hou\n",
    "EmaiL: daryl.hou08@myhunter.cuny.edu\n",
    "pod: rear left\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\1490952106.py:1: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  user_tweets = pd.read_csv(\"user_tweets.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_1</th>\n",
       "      <th>tweet_2</th>\n",
       "      <th>tweet_3</th>\n",
       "      <th>tweet_4</th>\n",
       "      <th>tweet_5</th>\n",
       "      <th>tweet_6</th>\n",
       "      <th>tweet_7</th>\n",
       "      <th>tweet_8</th>\n",
       "      <th>tweet_9</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_191</th>\n",
       "      <th>tweet_192</th>\n",
       "      <th>tweet_193</th>\n",
       "      <th>tweet_194</th>\n",
       "      <th>tweet_195</th>\n",
       "      <th>tweet_196</th>\n",
       "      <th>tweet_197</th>\n",
       "      <th>tweet_198</th>\n",
       "      <th>tweet_199</th>\n",
       "      <th>tweet_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160881623</td>\n",
       "      <td>@andresitonieve Me he quedado igual estoy llor...</td>\n",
       "      <td>RT @heikala_art: Fragment of a Star ğŸ’« Celebrat...</td>\n",
       "      <td>RT @bananamisart: I heard it was BOtW's 3rd an...</td>\n",
       "      <td>RT @night_sprout: new banner time!! https://t....</td>\n",
       "      <td>RT @dealer_rug: Why is everyone buying toilet ...</td>\n",
       "      <td>@andresitonieve Amo el diseÃ±o de este personaje</td>\n",
       "      <td>RT @Tchaigothsky: UNFORTUNATELY I CANT STOP WA...</td>\n",
       "      <td>RT @_Ritao_: IT'S SO CUTE AHHHHHHHğŸ˜­ https://t....</td>\n",
       "      <td>RT @Lesfleursdmal: Os dejo esto por aquÃ­ por s...</td>\n",
       "      <td>...</td>\n",
       "      <td>NOOOOOOOOOOO MURCIA HA CAÃDO TAMBIÃ‰N ğŸ˜”ğŸ˜”ğŸ˜”</td>\n",
       "      <td>@ederugaruto Si te estÃ¡n amenazando de esa man...</td>\n",
       "      <td>19. Siempre me han encantado los dÃ­as de fuego...</td>\n",
       "      <td>RT @pupa_puuupa: 4ã€œ6 https://t.co/Hhdv33tWOi</td>\n",
       "      <td>RT @TANA_in_: ëœ¨ê±°ìš´ ì—¬ë¦„ ë°¤ì€ ê°€ê³  ë‚¨ì€ ê±´ ë³¼í’ˆì—†ì§€ë§Œ https://...</td>\n",
       "      <td>RT @Vivi95862484: â¤ï¸ğŸ’™ https://t.co/OAv2F1FKLc</td>\n",
       "      <td>RT @gomachino: ãƒŸãƒ„ãƒŠãƒ«ã®æ—¥ https://t.co/9b44lJtHDW</td>\n",
       "      <td>RT @_KUZUDANA_: â¤ï¸ãƒŸãƒ„ãƒŠãƒ«ã®æ—¥ğŸ’™ https://t.co/7wCGN8Wgl9</td>\n",
       "      <td>RT @Locarconio: ğŸ”´ Ciertos youtubers estÃ¡n en M...</td>\n",
       "      <td>RT @charllandsberg: Asexual women in South Afr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28968838</td>\n",
       "      <td>PLEASE VOTE, VOTE, VOTE FOR AMYBETH! thanks! i...</td>\n",
       "      <td>RT @sofeimous: Look at this cutie! Thank you f...</td>\n",
       "      <td>'kelangan talaga lumipat ng bahay, pero di ka ...</td>\n",
       "      <td>forgiveness and justice.\\nforgiveness with jus...</td>\n",
       "      <td>hirap maging babae no? #PamilyaKoPagkabuwag</td>\n",
       "      <td>eh damang-dama ko yung pagod ni luz, yung pago...</td>\n",
       "      <td>oo nga no? makes you think, what's your deal-b...</td>\n",
       "      <td>hay nako si apol timing fail talaga.\\n#Pamilya...</td>\n",
       "      <td>RT @tracy_erickson: Halimaw si Sylvia Sanchez....</td>\n",
       "      <td>...</td>\n",
       "      <td>RT @GingerSpirits: AB giving me Lucas content?...</td>\n",
       "      <td>RT @musicfanforeva2: god bless the writers of ...</td>\n",
       "      <td>RT @AtheerforAnne: @TahiraOsman4 https://t.co/...</td>\n",
       "      <td>RT @TahiraOsman4: Who can pinpoint the exact m...</td>\n",
       "      <td>RT @TahiraOsman4: Dear Gilbert,\\n\\nI'm throwin...</td>\n",
       "      <td>RT @TahiraOsman4: (ANNE NATION)\\n\\nwe are ever...</td>\n",
       "      <td>RT @TahiraOsman4: (what is love)\\n\\nloving is ...</td>\n",
       "      <td>RT @MikhaelVervoort: This Anne Nation. \\n\\nAdd...</td>\n",
       "      <td>RT @aqbeltran0612: To fail means weâ€™ve tried. ...</td>\n",
       "      <td>@Kermit5010 hahahahahahaha! tingnan natin! mah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2325006565</td>\n",
       "      <td>ã¿ã‚“ãªã‹ã‚‰ã®åŒ¿åè³ªå•ã‚’å‹Ÿé›†ä¸­ï¼\\n\\nã“ã‚“ãªè³ªå•ã«ç­”ãˆã¦ã‚‹ã‚ˆ\\nâ— Helloâ€¦\\n thi...</td>\n",
       "      <td>RT @shokami_movie: ä»Šæ—¥ã¯â€¦#ä½è—¤ã®æ—¥ ğŸ¤©ğŸ’“\\n\\næˆ‘ã‚‰ãŒåº§é•· #ä½è—¤å¤§æ¨¹...</td>\n",
       "      <td>RT @taiki__official: ä»Šæ—¥ã¯ #ä½è—¤ã®æ—¥ ã‚‰ã—ã„ã§ã™ğŸ˜‚</td>\n",
       "      <td>RT @Auditionblue: #Auditionblue ï¼”æœˆå·ç™ºå£²ä¸­ã§ã™ï¼\\næœ¬æ—¥ï¼“...</td>\n",
       "      <td>RT @generationsfext: #GENERATIONS WORLD TOUR 2...</td>\n",
       "      <td>PenguPooh\\nã„ã„ã­ã•ã‚ŒãŸæ•°:10(å‰æ—¥æ¯”:+6)\\nãƒ•ã‚©ãƒ­ãƒ¼ã—ãŸæ•°:5(å‰æ—¥æ¯”:+...</td>\n",
       "      <td>PenguPooh\\nãƒ„ã‚¤ãƒ¼ãƒˆæ•°:27(å‰æ—¥æ¯”:+5)\\nRTã—ãŸæ•°:19(å‰æ—¥æ¯”:+7)\\...</td>\n",
       "      <td>RT @HimeROAR: Does nails and puts on makeup to...</td>\n",
       "      <td>RT @kapsulecore: I hate to come on main and so...</td>\n",
       "      <td>...</td>\n",
       "      <td>RT @NYLONJAPAN: â€œä»Šé€±ä½•è²·ã†ï¼Ÿâ€ã‚’ãƒ†ãƒ¼ãƒã«ç”·å¥³å…±ã«æ¥½ã—ã‚ã‚‹ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ãƒšãƒ¼ã‚¸...</td>\n",
       "      <td>@coffeebourbon OMFG</td>\n",
       "      <td>RT @MLBJapan: ã€ #ãƒ‰ã‚¸ãƒ£ãƒ¼ã‚¹ ã€‘3åº¦ã® #ã‚µã‚¤ãƒ¤ãƒ³ã‚°è³ å·¦è…•ãŒä»Šæ—¥ã‚‚å¥½æŠ•ï¼3...</td>\n",
       "      <td>RT @LDH__TV: æœ¬æ—¥21æ™‚é…ä¿¡ğŸ“º\\nå¤§å¥½è©•ğŸ‰âœ¨16äººã§ã®æ…°å®‰æ—…è¡Œæœªå…¬é–‹ãƒ™ã‚¹ãƒˆ10ğŸ...</td>\n",
       "      <td>I pressed the up button on an elevator that wa...</td>\n",
       "      <td>ç¬‘</td>\n",
       "      <td>ã¨ã«ã‹ãã‚¢ãƒ›ã¿ãŸã„ãªæ­©ãæ–¹ã—ã¦ã‚‹ã£ã¦æƒ³åƒã—ã¦ã¿ã¦ã€</td>\n",
       "      <td>å‰ã‹ã‚‰ãƒšãƒ³ã‚®ãƒ³ã£ã½ã„ã£ã¦è¨€ã‚ã‚Œã¦ãŸã‚“ã ã‘ã©ãŠè…¹å¤§ãããªã£ã¦æ­©ãæ–¹ã¯ã‚‚ã£ã¨ãƒšãƒ³ã‚®ãƒ³ã£ã½ããªã£ãŸ...</td>\n",
       "      <td>RT @tkn0801: Alright guys, cherry blossom seas...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>907848145</td>\n",
       "      <td>RT @yep4andy: ğŸ¤·â€â™€ï¸\\n#EXOLSelcaDay \\n@weareoneE...</td>\n",
       "      <td>RT @lqldks: when is this from??? ğŸ˜­ğŸ˜­ğŸ˜­ https://t...</td>\n",
       "      <td>RT @j__nmyeon: since we're talking about suhÃ¸,...</td>\n",
       "      <td>I am supporting this fundraising page https://...</td>\n",
       "      <td>RT @cubsie_: Sun and moon outfits https://t.co...</td>\n",
       "      <td>@mouthysehun that looks like porridge AND TO D...</td>\n",
       "      <td>RT @weareoneEXO: Au Revoir, Paris (ì„¸í›ˆ)\\n\\nğŸ‘‰ğŸ»ht...</td>\n",
       "      <td>RT @sukaihan: this is definitely one of my fav...</td>\n",
       "      <td>RT @bblyds: oh to be watching the rain and lis...</td>\n",
       "      <td>...</td>\n",
       "      <td>RT @sehunownsme: [hunstagram] Remember to your...</td>\n",
       "      <td>RT @mishyeol: [ğŸ–¼WP] \\nEXO-L Welcome Kit Photo ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330237585</td>\n",
       "      <td>@DaryKiri_ Gracias a ti por apreciarlo ğŸ˜­âœŒğŸ»</td>\n",
       "      <td>RT @DaryKiri_: @nemuiryuu Gracias por poner en...</td>\n",
       "      <td>https://t.co/y8rrc8yJHi https://t.co/Xte4LM6LyK</td>\n",
       "      <td>RT @izzyhumair: Rt if you give Goths permissio...</td>\n",
       "      <td>@ageyoru Dw youâ€™re absolutely right, stan heal...</td>\n",
       "      <td>ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤® https://t.co/wn7bh40tGU</td>\n",
       "      <td>stop asking for my money cygames I donâ€™t have any</td>\n",
       "      <td>@vonfriedhof Desde luego se estÃ¡n esforzando e...</td>\n",
       "      <td>RT @Ryusei_Rainbow_: â€œIf youâ€™re going to start...</td>\n",
       "      <td>...</td>\n",
       "      <td>nothing as expected</td>\n",
       "      <td>this game was a mistake</td>\n",
       "      <td>fuck it i'm using my shitty 20 pulls i'm sad...</td>\n",
       "      <td>@kolveniks yo tambiÃ©n lo odio</td>\n",
       "      <td>https://t.co/kuvQvIHQei</td>\n",
       "      <td>oomf GOT HADES AND I NEED HADES</td>\n",
       "      <td>I wanna CRY.</td>\n",
       "      <td>@MasaruDz I HATE U...... omg please give</td>\n",
       "      <td>I wanna quit this game soooo bad</td>\n",
       "      <td>@DanaCWSF a una amiga igual... quÃ© horror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                            tweet_1  \\\n",
       "0   160881623  @andresitonieve Me he quedado igual estoy llor...   \n",
       "1    28968838  PLEASE VOTE, VOTE, VOTE FOR AMYBETH! thanks! i...   \n",
       "2  2325006565  ã¿ã‚“ãªã‹ã‚‰ã®åŒ¿åè³ªå•ã‚’å‹Ÿé›†ä¸­ï¼\\n\\nã“ã‚“ãªè³ªå•ã«ç­”ãˆã¦ã‚‹ã‚ˆ\\nâ— Helloâ€¦\\n thi...   \n",
       "3   907848145  RT @yep4andy: ğŸ¤·â€â™€ï¸\\n#EXOLSelcaDay \\n@weareoneE...   \n",
       "4  1330237585         @DaryKiri_ Gracias a ti por apreciarlo ğŸ˜­âœŒğŸ»   \n",
       "\n",
       "                                             tweet_2  \\\n",
       "0  RT @heikala_art: Fragment of a Star ğŸ’« Celebrat...   \n",
       "1  RT @sofeimous: Look at this cutie! Thank you f...   \n",
       "2  RT @shokami_movie: ä»Šæ—¥ã¯â€¦#ä½è—¤ã®æ—¥ ğŸ¤©ğŸ’“\\n\\næˆ‘ã‚‰ãŒåº§é•· #ä½è—¤å¤§æ¨¹...   \n",
       "3  RT @lqldks: when is this from??? ğŸ˜­ğŸ˜­ğŸ˜­ https://t...   \n",
       "4  RT @DaryKiri_: @nemuiryuu Gracias por poner en...   \n",
       "\n",
       "                                             tweet_3  \\\n",
       "0  RT @bananamisart: I heard it was BOtW's 3rd an...   \n",
       "1  'kelangan talaga lumipat ng bahay, pero di ka ...   \n",
       "2              RT @taiki__official: ä»Šæ—¥ã¯ #ä½è—¤ã®æ—¥ ã‚‰ã—ã„ã§ã™ğŸ˜‚   \n",
       "3  RT @j__nmyeon: since we're talking about suhÃ¸,...   \n",
       "4    https://t.co/y8rrc8yJHi https://t.co/Xte4LM6LyK   \n",
       "\n",
       "                                             tweet_4  \\\n",
       "0  RT @night_sprout: new banner time!! https://t....   \n",
       "1  forgiveness and justice.\\nforgiveness with jus...   \n",
       "2  RT @Auditionblue: #Auditionblue ï¼”æœˆå·ç™ºå£²ä¸­ã§ã™ï¼\\næœ¬æ—¥ï¼“...   \n",
       "3  I am supporting this fundraising page https://...   \n",
       "4  RT @izzyhumair: Rt if you give Goths permissio...   \n",
       "\n",
       "                                             tweet_5  \\\n",
       "0  RT @dealer_rug: Why is everyone buying toilet ...   \n",
       "1        hirap maging babae no? #PamilyaKoPagkabuwag   \n",
       "2  RT @generationsfext: #GENERATIONS WORLD TOUR 2...   \n",
       "3  RT @cubsie_: Sun and moon outfits https://t.co...   \n",
       "4  @ageyoru Dw youâ€™re absolutely right, stan heal...   \n",
       "\n",
       "                                             tweet_6  \\\n",
       "0    @andresitonieve Amo el diseÃ±o de este personaje   \n",
       "1  eh damang-dama ko yung pagod ni luz, yung pago...   \n",
       "2  PenguPooh\\nã„ã„ã­ã•ã‚ŒãŸæ•°:10(å‰æ—¥æ¯”:+6)\\nãƒ•ã‚©ãƒ­ãƒ¼ã—ãŸæ•°:5(å‰æ—¥æ¯”:+...   \n",
       "3  @mouthysehun that looks like porridge AND TO D...   \n",
       "4                ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤¢ğŸ¤® https://t.co/wn7bh40tGU   \n",
       "\n",
       "                                             tweet_7  \\\n",
       "0  RT @Tchaigothsky: UNFORTUNATELY I CANT STOP WA...   \n",
       "1  oo nga no? makes you think, what's your deal-b...   \n",
       "2  PenguPooh\\nãƒ„ã‚¤ãƒ¼ãƒˆæ•°:27(å‰æ—¥æ¯”:+5)\\nRTã—ãŸæ•°:19(å‰æ—¥æ¯”:+7)\\...   \n",
       "3  RT @weareoneEXO: Au Revoir, Paris (ì„¸í›ˆ)\\n\\nğŸ‘‰ğŸ»ht...   \n",
       "4  stop asking for my money cygames I donâ€™t have any   \n",
       "\n",
       "                                             tweet_8  \\\n",
       "0  RT @_Ritao_: IT'S SO CUTE AHHHHHHHğŸ˜­ https://t....   \n",
       "1  hay nako si apol timing fail talaga.\\n#Pamilya...   \n",
       "2  RT @HimeROAR: Does nails and puts on makeup to...   \n",
       "3  RT @sukaihan: this is definitely one of my fav...   \n",
       "4  @vonfriedhof Desde luego se estÃ¡n esforzando e...   \n",
       "\n",
       "                                             tweet_9  ...  \\\n",
       "0  RT @Lesfleursdmal: Os dejo esto por aquÃ­ por s...  ...   \n",
       "1  RT @tracy_erickson: Halimaw si Sylvia Sanchez....  ...   \n",
       "2  RT @kapsulecore: I hate to come on main and so...  ...   \n",
       "3  RT @bblyds: oh to be watching the rain and lis...  ...   \n",
       "4  RT @Ryusei_Rainbow_: â€œIf youâ€™re going to start...  ...   \n",
       "\n",
       "                                           tweet_191  \\\n",
       "0           NOOOOOOOOOOO MURCIA HA CAÃDO TAMBIÃ‰N ğŸ˜”ğŸ˜”ğŸ˜”   \n",
       "1  RT @GingerSpirits: AB giving me Lucas content?...   \n",
       "2  RT @NYLONJAPAN: â€œä»Šé€±ä½•è²·ã†ï¼Ÿâ€ã‚’ãƒ†ãƒ¼ãƒã«ç”·å¥³å…±ã«æ¥½ã—ã‚ã‚‹ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ãƒšãƒ¼ã‚¸...   \n",
       "3  RT @sehunownsme: [hunstagram] Remember to your...   \n",
       "4                                nothing as expected   \n",
       "\n",
       "                                           tweet_192  \\\n",
       "0  @ederugaruto Si te estÃ¡n amenazando de esa man...   \n",
       "1  RT @musicfanforeva2: god bless the writers of ...   \n",
       "2                                @coffeebourbon OMFG   \n",
       "3  RT @mishyeol: [ğŸ–¼WP] \\nEXO-L Welcome Kit Photo ...   \n",
       "4                            this game was a mistake   \n",
       "\n",
       "                                           tweet_193  \\\n",
       "0  19. Siempre me han encantado los dÃ­as de fuego...   \n",
       "1  RT @AtheerforAnne: @TahiraOsman4 https://t.co/...   \n",
       "2  RT @MLBJapan: ã€ #ãƒ‰ã‚¸ãƒ£ãƒ¼ã‚¹ ã€‘3åº¦ã® #ã‚µã‚¤ãƒ¤ãƒ³ã‚°è³ å·¦è…•ãŒä»Šæ—¥ã‚‚å¥½æŠ•ï¼3...   \n",
       "3                                                NaN   \n",
       "4    fuck it i'm using my shitty 20 pulls i'm sad...   \n",
       "\n",
       "                                           tweet_194  \\\n",
       "0       RT @pupa_puuupa: 4ã€œ6 https://t.co/Hhdv33tWOi   \n",
       "1  RT @TahiraOsman4: Who can pinpoint the exact m...   \n",
       "2  RT @LDH__TV: æœ¬æ—¥21æ™‚é…ä¿¡ğŸ“º\\nå¤§å¥½è©•ğŸ‰âœ¨16äººã§ã®æ…°å®‰æ—…è¡Œæœªå…¬é–‹ãƒ™ã‚¹ãƒˆ10ğŸ...   \n",
       "3                                                NaN   \n",
       "4                      @kolveniks yo tambiÃ©n lo odio   \n",
       "\n",
       "                                           tweet_195  \\\n",
       "0  RT @TANA_in_: ëœ¨ê±°ìš´ ì—¬ë¦„ ë°¤ì€ ê°€ê³  ë‚¨ì€ ê±´ ë³¼í’ˆì—†ì§€ë§Œ https://...   \n",
       "1  RT @TahiraOsman4: Dear Gilbert,\\n\\nI'm throwin...   \n",
       "2  I pressed the up button on an elevator that wa...   \n",
       "3                                                NaN   \n",
       "4                            https://t.co/kuvQvIHQei   \n",
       "\n",
       "                                           tweet_196  \\\n",
       "0      RT @Vivi95862484: â¤ï¸ğŸ’™ https://t.co/OAv2F1FKLc   \n",
       "1  RT @TahiraOsman4: (ANNE NATION)\\n\\nwe are ever...   \n",
       "2                                                  ç¬‘   \n",
       "3                                                NaN   \n",
       "4                    oomf GOT HADES AND I NEED HADES   \n",
       "\n",
       "                                           tweet_197  \\\n",
       "0      RT @gomachino: ãƒŸãƒ„ãƒŠãƒ«ã®æ—¥ https://t.co/9b44lJtHDW   \n",
       "1  RT @TahiraOsman4: (what is love)\\n\\nloving is ...   \n",
       "2                          ã¨ã«ã‹ãã‚¢ãƒ›ã¿ãŸã„ãªæ­©ãæ–¹ã—ã¦ã‚‹ã£ã¦æƒ³åƒã—ã¦ã¿ã¦ã€   \n",
       "3                                                NaN   \n",
       "4                                       I wanna CRY.   \n",
       "\n",
       "                                           tweet_198  \\\n",
       "0  RT @_KUZUDANA_: â¤ï¸ãƒŸãƒ„ãƒŠãƒ«ã®æ—¥ğŸ’™ https://t.co/7wCGN8Wgl9   \n",
       "1  RT @MikhaelVervoort: This Anne Nation. \\n\\nAdd...   \n",
       "2  å‰ã‹ã‚‰ãƒšãƒ³ã‚®ãƒ³ã£ã½ã„ã£ã¦è¨€ã‚ã‚Œã¦ãŸã‚“ã ã‘ã©ãŠè…¹å¤§ãããªã£ã¦æ­©ãæ–¹ã¯ã‚‚ã£ã¨ãƒšãƒ³ã‚®ãƒ³ã£ã½ããªã£ãŸ...   \n",
       "3                                                NaN   \n",
       "4           @MasaruDz I HATE U...... omg please give   \n",
       "\n",
       "                                           tweet_199  \\\n",
       "0  RT @Locarconio: ğŸ”´ Ciertos youtubers estÃ¡n en M...   \n",
       "1  RT @aqbeltran0612: To fail means weâ€™ve tried. ...   \n",
       "2  RT @tkn0801: Alright guys, cherry blossom seas...   \n",
       "3                                                NaN   \n",
       "4                   I wanna quit this game soooo bad   \n",
       "\n",
       "                                           tweet_200  \n",
       "0  RT @charllandsberg: Asexual women in South Afr...  \n",
       "1  @Kermit5010 hahahahahahaha! tingnan natin! mah...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4          @DanaCWSF a una amiga igual... quÃ© horror  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_tweets = pd.read_csv(\"user_tweets.csv\")\n",
    "user_tweets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_25192\\2512279015.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  user_tweets[new_col_name] = (user_tweets[col]\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import clean_tweet\n",
    "\n",
    "# Get all column names except 'id'\n",
    "tweet_columns = user_tweets.columns[1:]  # All columns except the first one\n",
    "\n",
    "# Create new cleaned columns with proper type conversion\n",
    "for col in tweet_columns:\n",
    "    # First convert the column to string type, handling NaN values\n",
    "    new_col_name = f'cleaned_{col}'\n",
    "    # Convert to string and handle NaN values in one step\n",
    "    user_tweets[new_col_name] = (user_tweets[col]\n",
    "                                .fillna('')  # Replace NaN with empty string\n",
    "                                .astype(str)  # Convert everything to string\n",
    "                                .replace('nan', '')  # Replace 'nan' string with empty string\n",
    "                                .apply(clean_tweet))  # Apply cleaning function\n",
    "\n",
    "# If you want to keep only the cleaned columns and the ID:\n",
    "cleaned_columns = ['id'] + [f'cleaned_{col}' for col in tweet_columns]\n",
    "cleaned_df = user_tweets[cleaned_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_tweet_1</th>\n",
       "      <th>cleaned_tweet_2</th>\n",
       "      <th>cleaned_tweet_3</th>\n",
       "      <th>cleaned_tweet_4</th>\n",
       "      <th>cleaned_tweet_5</th>\n",
       "      <th>cleaned_tweet_6</th>\n",
       "      <th>cleaned_tweet_7</th>\n",
       "      <th>cleaned_tweet_8</th>\n",
       "      <th>cleaned_tweet_9</th>\n",
       "      <th>...</th>\n",
       "      <th>cleaned_tweet_191</th>\n",
       "      <th>cleaned_tweet_192</th>\n",
       "      <th>cleaned_tweet_193</th>\n",
       "      <th>cleaned_tweet_194</th>\n",
       "      <th>cleaned_tweet_195</th>\n",
       "      <th>cleaned_tweet_196</th>\n",
       "      <th>cleaned_tweet_197</th>\n",
       "      <th>cleaned_tweet_198</th>\n",
       "      <th>cleaned_tweet_199</th>\n",
       "      <th>cleaned_tweet_200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160881623</td>\n",
       "      <td>me he quedado igual estoy llorando</td>\n",
       "      <td>rt  fragment of a star  celebrating my anniver...</td>\n",
       "      <td>rt  i heard it was botws 3rd anniversary and i...</td>\n",
       "      <td>rt  new banner time</td>\n",
       "      <td>rt  why is everyone buying toilet paper its th...</td>\n",
       "      <td>amo el diseo de este personaje</td>\n",
       "      <td>rt  unfortunately i cant stop watching this ti...</td>\n",
       "      <td>rt  its so cute ahhhhhhh</td>\n",
       "      <td>rt  os dejo esto por aqu por si estis teniendo...</td>\n",
       "      <td>...</td>\n",
       "      <td>nooooooooooo murcia ha cado tambin</td>\n",
       "      <td>si te estn amenazando de esa manera no tienes...</td>\n",
       "      <td>19 siempre me han encantado los das de fuegos ...</td>\n",
       "      <td>rt  46</td>\n",
       "      <td>rt</td>\n",
       "      <td>rt</td>\n",
       "      <td>rt</td>\n",
       "      <td>rt</td>\n",
       "      <td>rt   ciertos youtubers estn en madrid dando vu...</td>\n",
       "      <td>rt  asexual women in south africa suffer corre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28968838</td>\n",
       "      <td>please vote vote vote for amybeth thanks it wo...</td>\n",
       "      <td>rt  look at this cutie thank you for trusting ...</td>\n",
       "      <td>kelangan talaga lumipat ng bahay pero di ka na...</td>\n",
       "      <td>forgiveness and justice\\nforgiveness with just...</td>\n",
       "      <td>hirap maging babae no pamilyakopagkabuwag</td>\n",
       "      <td>eh damangdama ko yung pagod ni luz yung pagod ...</td>\n",
       "      <td>oo nga no makes you think whats your dealbreak...</td>\n",
       "      <td>hay nako si apol timing fail talaga\\npamilyako...</td>\n",
       "      <td>rt  halimaw si sylvia sanchez in every definit...</td>\n",
       "      <td>...</td>\n",
       "      <td>rt  ab giving me lucas content we love to see ...</td>\n",
       "      <td>rt  god bless the writers of anne with an e</td>\n",
       "      <td>rt    \\nin all of these scenes i feel that ann...</td>\n",
       "      <td>rt  who can pinpoint the exact moment anne fal...</td>\n",
       "      <td>rt  dear gilbert\\n\\nim throwing the rules out ...</td>\n",
       "      <td>rt  anne nation\\n\\nwe are everyone \\nfrom ever...</td>\n",
       "      <td>rt  what is love\\n\\nloving is learning \\nthat ...</td>\n",
       "      <td>rt  this anne nation \\n\\nadded active accounts...</td>\n",
       "      <td>rt  to fail means weve tried to be hurt means ...</td>\n",
       "      <td>hahahahahahaha tingnan natin mahal ko nga per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2325006565</td>\n",
       "      <td>\\n\\n\\n hello\\n this is \\n \\n \\n 2\\n \\n\\n</td>\n",
       "      <td>rt   \\n\\n  \\n\\n\\n \\n522</td>\n",
       "      <td>rt</td>\n",
       "      <td>rt  auditionblue \\n\\n  \\n\\n</td>\n",
       "      <td>rt  generations world tour 2015 generation ex\\...</td>\n",
       "      <td>pengupooh\\n106\\n56\\n31\\n</td>\n",
       "      <td>pengupooh\\n275\\nrt197\\nrt11\\n02\\n10\\n2511</td>\n",
       "      <td>rt  does nails and puts on makeup to take self...</td>\n",
       "      <td>rt  i hate to come on main and sound like im b...</td>\n",
       "      <td>...</td>\n",
       "      <td>rt  get new stuff\\n\\ncheck</td>\n",
       "      <td>omfg</td>\n",
       "      <td>rt    3  304\\n\\n</td>\n",
       "      <td>rt  21\\n1610\\n\\nmcng\\n\\n\\n\\nld</td>\n",
       "      <td>i pressed the up button on an elevator that wa...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>rt  alright guys cherry blossom season is comi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>907848145</td>\n",
       "      <td>rt  \\nexolselcaday \\n</td>\n",
       "      <td>rt  when is this from</td>\n",
       "      <td>rt  since were talking about suh a friendly re...</td>\n",
       "      <td>i am supporting this fundraising page  and i t...</td>\n",
       "      <td>rt  sun and moon outfits</td>\n",
       "      <td>that looks like porridge and to drain it is t...</td>\n",
       "      <td>rt  au revoir paris \\n\\n\\n\\n sehun exo  weareo...</td>\n",
       "      <td>rt  this is definitely one of my fav seho mome...</td>\n",
       "      <td>rt  oh to be watching the rain and listening t...</td>\n",
       "      <td>...</td>\n",
       "      <td>rt  hunstagram remember to your vitamins its c...</td>\n",
       "      <td>rt  wp \\nexol welcome kit photo wallpapers \\n\\...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1330237585</td>\n",
       "      <td>gracias a ti por apreciarlo</td>\n",
       "      <td>rt   gracias por poner en mi tl contenido de a...</td>\n",
       "      <td></td>\n",
       "      <td>rt  rt if you give goths permission to pose an...</td>\n",
       "      <td>dw youre absolutely right stan healing good p...</td>\n",
       "      <td></td>\n",
       "      <td>stop asking for my money cygames i dont have any</td>\n",
       "      <td>desde luego se estn esforzando en que nos pla...</td>\n",
       "      <td>rt  if youre going to start gbf i recommend do...</td>\n",
       "      <td>...</td>\n",
       "      <td>nothing as expected</td>\n",
       "      <td>this game was a mistake</td>\n",
       "      <td>fuck it im using my shitty 20 pulls im sad</td>\n",
       "      <td>yo tambin lo odio</td>\n",
       "      <td></td>\n",
       "      <td>oomf got hades and i need hades</td>\n",
       "      <td>i wanna cry</td>\n",
       "      <td>i hate u omg please give</td>\n",
       "      <td>i wanna quit this game soooo bad</td>\n",
       "      <td>a una amiga igual qu horror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                    cleaned_tweet_1  \\\n",
       "0   160881623                 me he quedado igual estoy llorando   \n",
       "1    28968838  please vote vote vote for amybeth thanks it wo...   \n",
       "2  2325006565           \\n\\n\\n hello\\n this is \\n \\n \\n 2\\n \\n\\n   \n",
       "3   907848145                             rt  \\nexolselcaday \\n    \n",
       "4  1330237585                       gracias a ti por apreciarlo    \n",
       "\n",
       "                                     cleaned_tweet_2  \\\n",
       "0  rt  fragment of a star  celebrating my anniver...   \n",
       "1  rt  look at this cutie thank you for trusting ...   \n",
       "2                           rt   \\n\\n  \\n\\n\\n \\n522    \n",
       "3                            rt  when is this from     \n",
       "4  rt   gracias por poner en mi tl contenido de a...   \n",
       "\n",
       "                                     cleaned_tweet_3  \\\n",
       "0  rt  i heard it was botws 3rd anniversary and i...   \n",
       "1  kelangan talaga lumipat ng bahay pero di ka na...   \n",
       "2                                             rt       \n",
       "3  rt  since were talking about suh a friendly re...   \n",
       "4                                                      \n",
       "\n",
       "                                     cleaned_tweet_4  \\\n",
       "0                               rt  new banner time    \n",
       "1  forgiveness and justice\\nforgiveness with just...   \n",
       "2                        rt  auditionblue \\n\\n  \\n\\n   \n",
       "3  i am supporting this fundraising page  and i t...   \n",
       "4  rt  rt if you give goths permission to pose an...   \n",
       "\n",
       "                                     cleaned_tweet_5  \\\n",
       "0  rt  why is everyone buying toilet paper its th...   \n",
       "1          hirap maging babae no pamilyakopagkabuwag   \n",
       "2  rt  generations world tour 2015 generation ex\\...   \n",
       "3                          rt  sun and moon outfits    \n",
       "4   dw youre absolutely right stan healing good p...   \n",
       "\n",
       "                                     cleaned_tweet_6  \\\n",
       "0                     amo el diseo de este personaje   \n",
       "1  eh damangdama ko yung pagod ni luz yung pagod ...   \n",
       "2                           pengupooh\\n106\\n56\\n31\\n   \n",
       "3   that looks like porridge and to drain it is t...   \n",
       "4                                                      \n",
       "\n",
       "                                     cleaned_tweet_7  \\\n",
       "0  rt  unfortunately i cant stop watching this ti...   \n",
       "1  oo nga no makes you think whats your dealbreak...   \n",
       "2          pengupooh\\n275\\nrt197\\nrt11\\n02\\n10\\n2511   \n",
       "3  rt  au revoir paris \\n\\n\\n\\n sehun exo  weareo...   \n",
       "4   stop asking for my money cygames i dont have any   \n",
       "\n",
       "                                     cleaned_tweet_8  \\\n",
       "0                          rt  its so cute ahhhhhhh    \n",
       "1  hay nako si apol timing fail talaga\\npamilyako...   \n",
       "2  rt  does nails and puts on makeup to take self...   \n",
       "3  rt  this is definitely one of my fav seho mome...   \n",
       "4   desde luego se estn esforzando en que nos pla...   \n",
       "\n",
       "                                     cleaned_tweet_9  ...  \\\n",
       "0  rt  os dejo esto por aqu por si estis teniendo...  ...   \n",
       "1  rt  halimaw si sylvia sanchez in every definit...  ...   \n",
       "2  rt  i hate to come on main and sound like im b...  ...   \n",
       "3  rt  oh to be watching the rain and listening t...  ...   \n",
       "4  rt  if youre going to start gbf i recommend do...  ...   \n",
       "\n",
       "                                   cleaned_tweet_191  \\\n",
       "0                nooooooooooo murcia ha cado tambin    \n",
       "1  rt  ab giving me lucas content we love to see ...   \n",
       "2                        rt  get new stuff\\n\\ncheck    \n",
       "3  rt  hunstagram remember to your vitamins its c...   \n",
       "4                                nothing as expected   \n",
       "\n",
       "                                   cleaned_tweet_192  \\\n",
       "0   si te estn amenazando de esa manera no tienes...   \n",
       "1        rt  god bless the writers of anne with an e   \n",
       "2                                               omfg   \n",
       "3  rt  wp \\nexol welcome kit photo wallpapers \\n\\...   \n",
       "4                            this game was a mistake   \n",
       "\n",
       "                                   cleaned_tweet_193  \\\n",
       "0  19 siempre me han encantado los das de fuegos ...   \n",
       "1  rt    \\nin all of these scenes i feel that ann...   \n",
       "2                                  rt    3  304\\n\\n    \n",
       "3                                                      \n",
       "4         fuck it im using my shitty 20 pulls im sad   \n",
       "\n",
       "                                   cleaned_tweet_194  \\\n",
       "0                                            rt  46    \n",
       "1  rt  who can pinpoint the exact moment anne fal...   \n",
       "2                     rt  21\\n1610\\n\\nmcng\\n\\n\\n\\nld   \n",
       "3                                                      \n",
       "4                                  yo tambin lo odio   \n",
       "\n",
       "                                   cleaned_tweet_195  \\\n",
       "0                                        rt            \n",
       "1  rt  dear gilbert\\n\\nim throwing the rules out ...   \n",
       "2  i pressed the up button on an elevator that wa...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                   cleaned_tweet_196  \\\n",
       "0                                              rt      \n",
       "1  rt  anne nation\\n\\nwe are everyone \\nfrom ever...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                    oomf got hades and i need hades   \n",
       "\n",
       "                                   cleaned_tweet_197  \\\n",
       "0                                              rt      \n",
       "1  rt  what is love\\n\\nloving is learning \\nthat ...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                        i wanna cry   \n",
       "\n",
       "                                   cleaned_tweet_198  \\\n",
       "0                                              rt      \n",
       "1  rt  this anne nation \\n\\nadded active accounts...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                           i hate u omg please give   \n",
       "\n",
       "                                   cleaned_tweet_199  \\\n",
       "0  rt   ciertos youtubers estn en madrid dando vu...   \n",
       "1  rt  to fail means weve tried to be hurt means ...   \n",
       "2  rt  alright guys cherry blossom season is comi...   \n",
       "3                                                      \n",
       "4                   i wanna quit this game soooo bad   \n",
       "\n",
       "                                   cleaned_tweet_200  \n",
       "0  rt  asexual women in south africa suffer corre...  \n",
       "1   hahahahahahaha tingnan natin mahal ko nga per...  \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                        a una amiga igual qu horror  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
